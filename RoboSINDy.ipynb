{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dab3865",
   "metadata": {},
   "source": [
    "# RoboSINDy: Project Introduction\n",
    "\n",
    "**Authors**: Julian Skifstad and Advaith Balaji\n",
    "\n",
    "This notebook implements the paper \"Data-driven discovery of coordinates and governing equations\" by Champion et al. on the Franka Panda Arm. The goal is to compare this method with e2c. This work aims to explore and evaluate the performance of these approaches in a robotic planar pushing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a706c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ea91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from numpngw import write_apng\n",
    "from IPython.display import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.panda_pushing_env import PandaImageSpacePushingEnv\n",
    "from utils.visualizers import GIFVisualizer, NotebookVisualizer\n",
    "from utils.utils import *\n",
    "from sindy.SINDy import RoboSINDy, SindyDataset, NormalizationTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4515394",
   "metadata": {},
   "source": [
    "Visualize panda arm environment in gym. Executes 3 random pushes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e082348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Create the visualizer\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "hfig = display(fig, display_id=True)\n",
    "visualizer = NotebookVisualizer(fig=fig, hfig=hfig)\n",
    "\n",
    "# Initialize the simulation environment\n",
    "env = PandaImageSpacePushingEnv(visualizer=visualizer,\n",
    "                                render_non_push_motions=True,\n",
    "                                camera_heigh=800,\n",
    "                                camera_width=800,\n",
    "                                grayscale=True,\n",
    "                                done_at_goal=False)\n",
    "env.reset()\n",
    "# Perform a sequence of 3 random actions:\n",
    "states = []\n",
    "for i in tqdm(range(3)):\n",
    "    action_i = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action_i)\n",
    "    states.append(state)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "view_states(states)\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a83103",
   "metadata": {},
   "source": [
    "Collect a dataset npy file that also included the state_derivatives. This will open the npy file in dataset_path and compute the state discrete time derivatives using central difference formula. It will then repackage states, actions, and state derivatives into a new .npy file which we can use as our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fdb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"datasets/pushing_image_data.npy\"\n",
    "dt = 1/240.0\n",
    "\n",
    "\n",
    "data_npy = np.load(dataset_path, allow_pickle=True)\n",
    "\n",
    "samples = []\n",
    "for item in data_npy:\n",
    "    \n",
    "    states = item['states']\n",
    "    actions = item['actions']\n",
    "    state_derivatives = []\n",
    "    for i in range(1, len(states)-1):\n",
    "        state_derivative = (states[i+1] - states[i-1]) / dt\n",
    "        state_derivatives.append(state_derivative)\n",
    "    state_derivatives = np.array(state_derivatives)\n",
    "\n",
    "    for i, state in enumerate(states[1:-1]):\n",
    "        sample = {\n",
    "            'state': state,\n",
    "            'action': actions[i],\n",
    "            'state_derivative': state_derivatives[i]\n",
    "        }\n",
    "        samples.append(sample)\n",
    "\n",
    "# print info about samples\n",
    "print(f\"Number of samples: {len(samples)}\")\n",
    "print(f\"Sample state shape: {samples[0]['state'].shape}\")\n",
    "print(f\"Sample action shape: {samples[0]['action'].shape}\")\n",
    "print(f\"Sample state derivative shape: {samples[0]['state_derivative'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa089535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some training and datset parameters\n",
    "val_fraction = 0.2\n",
    "batch_size = 64\n",
    "num_epochs = 75000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e1bff",
   "metadata": {},
   "source": [
    "The cell below will construct the Dataset used for RoboSINDy. It reads each sample from the .npy samples we created, normalizes each state and state derivatives, and constructs a dataloader to be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843af0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SindyDataset(data=samples)\n",
    "\n",
    "val_size = int(val_fraction * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "tot_train_states = []\n",
    "tot_train_state_derivatives = []\n",
    "for i in range(len(train_loader.dataset)):\n",
    "    s = train_loader.dataset[i]['states']   \n",
    "    sd = train_loader.dataset[i]['state_derivatives']  \n",
    "    tot_train_states.append(s.unsqueeze(0))\n",
    "    tot_train_state_derivatives.append(sd.unsqueeze(0))\n",
    "tot_train_states = torch.cat(tot_train_states,dim=0)  \n",
    "tot_train_state_derivatives = torch.cat(tot_train_state_derivatives, dim=0)  # (N,C,H,W)\n",
    "\n",
    "mean_s = tot_train_states .mean(dim=(0,2,3))\n",
    "std_s = tot_train_states .std( dim=(0,2,3))\n",
    "mean_sd = tot_train_state_derivatives.mean(dim=(0,2,3))\n",
    "std_sd = tot_train_state_derivatives.std( dim=(0,2,3))\n",
    "\n",
    "normalization_constants = {\n",
    "  'mean_state': mean_s,              \n",
    "  'std_state':  std_s,               \n",
    "  'mean_state_derivative': mean_sd,  \n",
    "  'std_state_derivative': std_sd,    \n",
    "}\n",
    "\n",
    "norm_tr = NormalizationTransform(normalization_constants)\n",
    "train_data.dataset.transform = norm_tr\n",
    "val_data.dataset.transform = norm_tr\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "print(f\"Loaded {len(train_loader.dataset)} training samples and {len(val_loader.dataset)} validation samples.\\n\")\n",
    "\n",
    "# get one sample and check quality\n",
    "sample = train_loader.dataset[0]\n",
    "print(f\"Sample state shape: {sample['states'].shape}\")\n",
    "print(f\"Sample action shape: {sample['actions'].shape}\")\n",
    "print(f\"Sample state derivative shape: {sample['state_derivatives'].shape}\")\n",
    "print(f\"Sample state: {sample['states']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "model = RoboSINDy(input_dim=32*32*1, batch_size=batch_size)\n",
    "\n",
    "model.train_model(train_loader, num_epochs=num_epochs, learning_rate=0.001)\n",
    "\n",
    "#save the model\n",
    "model_path = 'trained_models/sindy_model.pt'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Xi coefficients:\")\n",
    "\n",
    "# print in decimal form\n",
    "for i in range(len(model.xi_coefficients)):\n",
    "    for j in range(len(model.xi_coefficients[i])):\n",
    "       print(model.xi_coefficients[i, j].detach().numpy(), end=\", \")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
